# Copy this to .env and configure

# LLM Setup - Pick one option:

# Option 1: Ollama (runs locally, no API key needed)
# Install from ollama.com, then: ollama pull llama3
LLM_PROVIDER=ollama
LLM_MODEL=llama3
LLM_BASE_URL=http://localhost:11434

# Option 2: OpenAI (cloud, costs money)
# Get key from: https://platform.openai.com/api-keys
# LLM_PROVIDER=openai
# OPENAI_API_KEY=sk-your_key_here
# OPENAI_BASE_URL=https://api.openai.com/v1

# Option 3: Groq (free cloud option, uses OpenAI-compatible API)
# Get key from: https://console.groq.com
# LLM_PROVIDER=openai
# LLM_MODEL=llama-3.1-70b-versatile
# OPENAI_API_KEY=gsk_your_key_here
# OPENAI_BASE_URL=https://api.groq.com/openai/v1

# App Settings
LOG_LEVEL=INFO
OUTPUT_DIRECTORY=./output
CACHE_DIRECTORY=./.cache

# Defaults
REPORT_TYPE=academic
OUTPUT_FORMAT=docx
INCLUDE_CODE_SNIPPETS=false
DIAGRAM_STYLE=standard

PLAGIARISM_CHECK_ENABLED=true
MAX_SIMILARITY_THRESHOLD=0.3
